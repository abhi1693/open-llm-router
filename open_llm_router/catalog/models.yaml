version: 1
metadata_presets:
  reasoning_tools_ctx200000_out16384:
    capabilities:
    - chat
    - tool_use
    - reasoning
    - streaming
    - json_mode
    limits:
      context_tokens: 200000
      max_output_tokens: 16384
      min_input_chars: 1
  vision_ctx1048576_out8192:
    capabilities:
    - chat
    - vision
    - tool_use
    - streaming
    - json_mode
    limits:
      context_tokens: 1048576
      max_output_tokens: 8192
      min_input_chars: 1
  reasoning_ctx128000_out16384:
    capabilities:
    - chat
    - reasoning
    - streaming
    limits:
      context_tokens: 128000
      max_output_tokens: 16384
      min_input_chars: 1
  reasoning_ctx128000_out8192:
    capabilities:
    - chat
    - reasoning
    - streaming
    limits:
      context_tokens: 128000
      max_output_tokens: 8192
      min_input_chars: 1
  chat_ctx128000_out8192:
    capabilities:
    - chat
    - streaming
    limits:
      context_tokens: 128000
      max_output_tokens: 8192
      min_input_chars: 1
  chat_ctx128000_out4096:
    capabilities:
    - chat
    - streaming
    limits:
      context_tokens: 128000
      max_output_tokens: 4096
      min_input_chars: 1
  reasoning_ctx128000_out4096:
    capabilities:
    - chat
    - reasoning
    - streaming
    limits:
      context_tokens: 128000
      max_output_tokens: 4096
      min_input_chars: 1
  code_ctx128000_out4096:
    capabilities:
    - chat
    - code
    - streaming
    limits:
      context_tokens: 128000
      max_output_tokens: 4096
      min_input_chars: 1
  code_ctx131072_out1024:
    capabilities:
    - chat
    - code
    - streaming
    limits:
      context_tokens: 131072
      max_output_tokens: 1024
      min_input_chars: 1
  reasoning_ctx131072_out4096:
    capabilities:
    - chat
    - reasoning
    - streaming
    limits:
      context_tokens: 131072
      max_output_tokens: 4096
      min_input_chars: 1
  chat_ctx32768_out4096:
    capabilities:
    - chat
    - streaming
    limits:
      context_tokens: 32768
      max_output_tokens: 4096
      min_input_chars: 1
  chat_ctx131072_out1024:
    capabilities:
    - chat
    - streaming
    limits:
      context_tokens: 131072
      max_output_tokens: 1024
      min_input_chars: 1
models:
- id: gpt-5.2
  provider: openai-codex
  aliases: []
  costs:
    input_per_1k: 0.00175
    output_per_1k: 0.014
  priors:
    quality_bias: 0.68
    quality_sensitivity: 2.0
    latency_ms: 1150
    failure_rate: 0.03
  created: 1765389775
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: gpt-5.2-codex
  provider: openai-codex
  aliases: []
  costs:
    input_per_1k: 0.00175
    output_per_1k: 0.014
  priors:
    quality_bias: 0.74
    quality_sensitivity: 2.2
    latency_ms: 1300
    failure_rate: 0.032
  created: 1768409315
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: balanced
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.65
    general: 0.55
    instruction_following: 0.45
    image: -0.9
- id: gpt-5.3
  provider: openai-codex
  aliases: []
  costs:
    input_per_1k: 0.0023
    output_per_1k: 0.0078
  priors:
    quality_bias: 0.78
    quality_sensitivity: 2.35
    latency_ms: 1350
    failure_rate: 0.032
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: premium
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: gpt-5.3-codex
  provider: openai-codex
  aliases: []
  costs:
    input_per_1k: 0.0025
    output_per_1k: 0.0085
  priors:
    quality_bias: 0.8
    quality_sensitivity: 2.45
    latency_ms: 1450
    failure_rate: 0.035
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: premium
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.65
    general: 0.55
    instruction_following: 0.45
    image: -0.9
- id: gpt-5.3-codex-spark
  provider: openai-codex
  aliases: []
  costs:
    input_per_1k: 0.0021
    output_per_1k: 0.0068
  priors:
    quality_bias: 0.75
    quality_sensitivity: 2.2
    latency_ms: 980
    failure_rate: 0.03
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: balanced
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.65
    general: 0.55
    instruction_following: 0.45
    image: -0.9
- id: gpt-5.2
  provider: openai
  aliases: []
  costs:
    input_per_1k: 0.00175
    output_per_1k: 0.014
  priors:
    quality_bias: 0.7
    quality_sensitivity: 2.1
    latency_ms: 1080
    failure_rate: 0.028
  created: 1765389775
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: gemini-2.5-flash
  provider: gemini
  aliases: []
  costs:
    input_per_1k: 0.0003
    output_per_1k: 0.0025
  priors:
    quality_bias: 0.45
    quality_sensitivity: 1.25
    latency_ms: 700
    failure_rate: 0.025
  created: 1750172488
  metadata_preset: vision_ctx1048576_out8192
  tier: economy
  type: multimodal
  task_affinity:
    coding: 0.35
    thinking: 0.5
    general: 0.75
    instruction_following: 0.7
    image: 1.0
- id: gemini-2.5-flash-lite
  provider: gemini
  aliases: []
  costs:
    input_per_1k: 0.0001
    output_per_1k: 0.0004
  priors:
    quality_bias: 0.35
    quality_sensitivity: 1.05
    latency_ms: 520
    failure_rate: 0.022
  created: 1753200276
  metadata_preset: vision_ctx1048576_out8192
  tier: economy
  type: multimodal
  task_affinity:
    coding: 0.35
    thinking: 0.5
    general: 0.75
    instruction_following: 0.7
    image: 1.0
- id: z-ai/glm5
  provider: nvidia
  aliases:
  - glm5
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.8
    latency_ms: 950
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: moonshotai/kimi-k2.5
  provider: nvidia
  aliases:
  - kimi-k2.5
  costs:
    input_per_1k: 0.00023
    output_per_1k: 0.003
  priors:
    quality_bias: 0.67
    quality_sensitivity: 1.95
    latency_ms: 980
    failure_rate: 0.03
  created: 1769487076
  metadata_preset: reasoning_ctx128000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: deepseek-ai/deepseek-v3.2
  provider: nvidia
  aliases:
  - deepseek-v3.2
  costs:
    input_per_1k: 0.00026
    output_per_1k: 0.00038
  priors:
    quality_bias: 0.69
    quality_sensitivity: 2.0
    latency_ms: 1020
    failure_rate: 0.03
  created: 1764594642
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: deepseek-ai/deepseek-v3.1-terminus
  provider: nvidia
  aliases:
  - deepseek-v3.1-terminus
  costs:
    input_per_1k: 0.00021
    output_per_1k: 0.00079
  priors:
    quality_bias: 0.66
    quality_sensitivity: 1.95
    latency_ms: 1040
    failure_rate: 0.03
  created: 1758548275
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: deepseek-ai/deepseek-v3.1
  provider: nvidia
  aliases:
  - deepseek-v3.1
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.65
    quality_sensitivity: 1.9
    latency_ms: 1010
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: z-ai/glm4.7
  provider: nvidia
  aliases:
  - glm4.7
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.64
    quality_sensitivity: 1.85
    latency_ms: 1000
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: minimaxai/minimax-m2.1
  provider: nvidia
  aliases:
  - minimax-m2.1
  costs:
    input_per_1k: 0.00027
    output_per_1k: 0.00095
  priors:
    quality_bias: 0.63
    quality_sensitivity: 1.8
    latency_ms: 990
    failure_rate: 0.03
  created: 1766454997
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: minimaxai/minimax-m2
  provider: nvidia
  aliases:
  - minimax-m2
  costs:
    input_per_1k: 0.000255
    output_per_1k: 0.001
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.75
    latency_ms: 985
    failure_rate: 0.03
  created: 1761252093
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: moonshotai/kimi-k2-thinking
  provider: nvidia
  aliases:
  - kimi-k2-thinking
  costs:
    input_per_1k: 0.00047
    output_per_1k: 0.002
  priors:
    quality_bias: 0.68
    quality_sensitivity: 2.0
    latency_ms: 995
    failure_rate: 0.03
  created: 1762440622
  metadata_preset: reasoning_ctx128000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: moonshotai/kimi-k2-instruct-0905
  provider: nvidia
  aliases:
  - kimi-k2-instruct-0905
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.66
    quality_sensitivity: 1.9
    latency_ms: 980
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out4096
  tier: balanced
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: moonshotai/kimi-k2-instruct
  provider: nvidia
  aliases:
  - kimi-k2-instruct
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.65
    quality_sensitivity: 1.85
    latency_ms: 975
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out4096
  tier: balanced
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: qwen/qwen3.5-397b-a17b
  provider: nvidia
  aliases:
  - qwen3.5-397b-a17b
  costs:
    input_per_1k: 0.00015
    output_per_1k: 0.001
  priors:
    quality_bias: 0.7
    quality_sensitivity: 2.05
    latency_ms: 1030
    failure_rate: 0.03
  created: 1771223018
  metadata_preset: reasoning_ctx128000_out16384
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: qwen/qwen3-next-80b-a3b-instruct
  provider: nvidia
  aliases:
  - qwen3-next-80b-a3b-instruct
  costs:
    input_per_1k: 9.0e-05
    output_per_1k: 0.0011
  priors:
    quality_bias: 0.67
    quality_sensitivity: 1.95
    latency_ms: 980
    failure_rate: 0.03
  created: 1757612213
  metadata_preset: chat_ctx128000_out4096
  tier: balanced
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: qwen/qwen3-next-80b-a3b-thinking
  provider: nvidia
  aliases:
  - qwen3-next-80b-a3b-thinking
  costs:
    input_per_1k: 0.00015
    output_per_1k: 0.0012
  priors:
    quality_bias: 0.69
    quality_sensitivity: 2.0
    latency_ms: 995
    failure_rate: 0.03
  created: 1757612284
  metadata_preset: reasoning_ctx128000_out4096
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: qwen/qwen3-coder-480b-a35b-instruct
  provider: nvidia
  aliases:
  - qwen3-coder-480b-a35b-instruct
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.72
    quality_sensitivity: 2.1
    latency_ms: 1040
    failure_rate: 0.03
  metadata_preset: code_ctx128000_out4096
  tier: balanced
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.65
    general: 0.55
    instruction_following: 0.45
    image: -0.9
- id: qwen/qwen3-235b-a22b
  provider: nvidia
  aliases:
  - qwen3-235b-a22b
  costs:
    input_per_1k: 0.000455
    output_per_1k: 0.00182
  priors:
    quality_bias: 0.71
    quality_sensitivity: 2.05
    latency_ms: 1015
    failure_rate: 0.03
  created: 1745875757
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: qwen/qwen2.5-coder-32b-instruct
  provider: nvidia
  aliases:
  - qwen2.5-coder-32b-instruct
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.6
    quality_sensitivity: 1.75
    latency_ms: 900
    failure_rate: 0.03
  metadata_preset: code_ctx131072_out1024
  tier: balanced
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.65
    general: 0.55
    instruction_following: 0.45
    image: -0.9
- id: qwen/qwq-32b
  provider: nvidia
  aliases:
  - qwq-32b
  costs:
    input_per_1k: 0.00015
    output_per_1k: 0.0004
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.85
    latency_ms: 930
    failure_rate: 0.03
  created: 1741208814
  metadata_preset: reasoning_ctx131072_out4096
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.95
    general: 0.75
    instruction_following: 0.55
    image: -0.7
- id: qwen/qwen2-7b-instruct
  provider: nvidia
  aliases:
  - qwen2-7b-instruct
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.48
    quality_sensitivity: 1.35
    latency_ms: 720
    failure_rate: 0.03
  metadata_preset: chat_ctx32768_out4096
  tier: economy
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: qwen/qwen2.5-7b-instruct
  provider: nvidia
  aliases:
  - qwen2.5-7b-instruct
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.53
    quality_sensitivity: 1.45
    latency_ms: 740
    failure_rate: 0.03
  metadata_preset: chat_ctx131072_out1024
  tier: economy
  type: text
  task_affinity:
    coding: 0.35
    thinking: 0.45
    general: 0.65
    instruction_following: 0.7
    image: -0.8
- id: qwen/qwen2.5-coder-7b-instruct
  provider: nvidia
  aliases:
  - qwen2.5-coder-7b-instruct
  costs:
    input_per_1k: 3.0e-05
    output_per_1k: 9.0e-05
  priors:
    quality_bias: 0.56
    quality_sensitivity: 1.55
    latency_ms: 760
    failure_rate: 0.03
  created: 1744734887
  metadata_preset: code_ctx131072_out1024
  tier: economy
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.65
    general: 0.55
    instruction_following: 0.45
    image: -0.9
- id: openai/gpt-4.1
  provider: github
  aliases:
  - gpt-4.1
  - openai/gpt-4.1
  costs:
    input_per_1k: 0.002
    output_per_1k: 0.008
  priors:
    quality_bias: 0.7
    quality_sensitivity: 2.0
    latency_ms: 1000
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.65
    thinking: 0.9
    general: 0.75
    instruction_following: 0.6
    image: -0.7
  created: 1744651385
- id: openai/gpt-4.1-mini
  provider: github
  aliases:
  - gpt-4.1-mini
  - openai/gpt-4.1-mini
  costs:
    input_per_1k: 0.0004
    output_per_1k: 0.0016
  priors:
    quality_bias: 0.58
    quality_sensitivity: 1.6
    latency_ms: 820
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.45
    thinking: 0.5
    general: 0.72
    instruction_following: 0.7
    image: -0.8
  created: 1744651381
- id: meta/Llama-3.3-70B-Instruct
  provider: github
  aliases:
  - llama-3.3-70b-instruct
  - meta/llama-3.3-70b-instruct
  - meta/Llama-3.3-70B-Instruct
  - github/meta/llama-3.3-70b-instruct
  - github/meta/Llama-3.3-70B-Instruct
  costs:
    input_per_1k: 0.0001
    output_per_1k: 0.00032
  priors:
    quality_bias: 0.56
    quality_sensitivity: 1.55
    latency_ms: 860
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.52
    thinking: 0.58
    general: 0.74
    instruction_following: 0.68
    image: -0.8
  created: 1733506137
- id: ai21-labs/AI21-Jamba-1.5-Large
  provider: github
  aliases:
  - ai21-labs/AI21-Jamba-1.5-Large
  - AI21-Jamba-1.5-Large
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.6
    quality_sensitivity: 1.7
    latency_ms: 900
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.48
    thinking: 0.55
    general: 0.76
    instruction_following: 0.7
    image: -0.8
- id: microsoft/Phi-4-reasoning
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.7
    quality_sensitivity: 1.95
    latency_ms: 980
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.6
    thinking: 0.9
    general: 0.72
    instruction_following: 0.62
    image: -0.7
- id: microsoft/Phi-4-multimodal-instruct
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.64
    quality_sensitivity: 1.75
    latency_ms: 950
    failure_rate: 0.03
  metadata_preset: vision_ctx1048576_out8192
  tier: balanced
  type: multimodal
  task_affinity:
    coding: 0.5
    thinking: 0.62
    general: 0.78
    instruction_following: 0.72
    image: 1.0
- id: microsoft/Phi-4-mini-reasoning
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.7
    latency_ms: 840
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out4096
  tier: economy
  type: reasoning
  task_affinity:
    coding: 0.55
    thinking: 0.82
    general: 0.72
    instruction_following: 0.66
    image: -0.7
- id: microsoft/Phi-4-mini-instruct
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.56
    quality_sensitivity: 1.55
    latency_ms: 780
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.5
    thinking: 0.58
    general: 0.74
    instruction_following: 0.7
    image: -0.8
- id: microsoft/Phi-4
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.7
    latency_ms: 860
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.54
    thinking: 0.64
    general: 0.76
    instruction_following: 0.7
    image: -0.8
- id: openai/o4-mini
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.72
    quality_sensitivity: 2.05
    latency_ms: 920
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.62
    thinking: 0.9
    general: 0.74
    instruction_following: 0.64
    image: -0.7
- id: openai/o3-mini
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.68
    quality_sensitivity: 1.9
    latency_ms: 860
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: economy
  type: reasoning
  task_affinity:
    coding: 0.58
    thinking: 0.86
    general: 0.72
    instruction_following: 0.62
    image: -0.7
- id: openai/o3
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.76
    quality_sensitivity: 2.2
    latency_ms: 1050
    failure_rate: 0.03
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: premium
  type: reasoning
  task_affinity:
    coding: 0.66
    thinking: 0.94
    general: 0.76
    instruction_following: 0.66
    image: -0.7
- id: openai/o1-preview
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.72
    quality_sensitivity: 2.05
    latency_ms: 1120
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: premium
  type: reasoning
  task_affinity:
    coding: 0.6
    thinking: 0.9
    general: 0.72
    instruction_following: 0.62
    image: -0.7
- id: openai/o1-mini
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.64
    quality_sensitivity: 1.75
    latency_ms: 900
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out4096
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.56
    thinking: 0.82
    general: 0.7
    instruction_following: 0.62
    image: -0.7
- id: openai/o1
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.74
    quality_sensitivity: 2.1
    latency_ms: 1080
    failure_rate: 0.03
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: premium
  type: reasoning
  task_affinity:
    coding: 0.64
    thinking: 0.92
    general: 0.74
    instruction_following: 0.64
    image: -0.7
- id: openai/gpt-5-nano
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.6
    quality_sensitivity: 1.65
    latency_ms: 700
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out4096
  tier: economy
  type: text
  task_affinity:
    coding: 0.48
    thinking: 0.54
    general: 0.75
    instruction_following: 0.72
    image: -0.8
- id: openai/gpt-5-mini
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.66
    quality_sensitivity: 1.85
    latency_ms: 840
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.58
    thinking: 0.84
    general: 0.74
    instruction_following: 0.68
    image: -0.7
- id: openai/gpt-5-chat
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.7
    quality_sensitivity: 1.95
    latency_ms: 900
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.56
    thinking: 0.68
    general: 0.8
    instruction_following: 0.75
    image: -0.8
- id: openai/gpt-5
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.78
    quality_sensitivity: 2.25
    latency_ms: 1100
    failure_rate: 0.03
  metadata_preset: reasoning_tools_ctx200000_out16384
  tier: premium
  type: reasoning
  task_affinity:
    coding: 0.66
    thinking: 0.94
    general: 0.78
    instruction_following: 0.68
    image: -0.7
- id: openai/gpt-4o-mini
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.58
    quality_sensitivity: 1.55
    latency_ms: 760
    failure_rate: 0.03
  metadata_preset: vision_ctx1048576_out8192
  tier: economy
  type: multimodal
  task_affinity:
    coding: 0.46
    thinking: 0.54
    general: 0.78
    instruction_following: 0.74
    image: 1.0
- id: openai/gpt-4o
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.68
    quality_sensitivity: 1.9
    latency_ms: 900
    failure_rate: 0.03
  metadata_preset: vision_ctx1048576_out8192
  tier: balanced
  type: multimodal
  task_affinity:
    coding: 0.52
    thinking: 0.64
    general: 0.8
    instruction_following: 0.76
    image: 1.0
- id: openai/gpt-4.1-nano
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.52
    quality_sensitivity: 1.4
    latency_ms: 680
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out4096
  tier: economy
  type: text
  task_affinity:
    coding: 0.44
    thinking: 0.5
    general: 0.72
    instruction_following: 0.7
    image: -0.8
- id: meta/Meta-Llama-3.1-8B-Instruct
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.52
    quality_sensitivity: 1.45
    latency_ms: 740
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.46
    thinking: 0.52
    general: 0.72
    instruction_following: 0.7
    image: -0.8
- id: meta/Meta-Llama-3.1-405B-Instruct
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.7
    quality_sensitivity: 1.95
    latency_ms: 1100
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: premium
  type: text
  task_affinity:
    coding: 0.58
    thinking: 0.68
    general: 0.78
    instruction_following: 0.74
    image: -0.8
- id: meta/Llama-4-Scout-17B-16E-Instruct
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.7
    latency_ms: 860
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.52
    thinking: 0.6
    general: 0.76
    instruction_following: 0.72
    image: -0.8
- id: cohere/Cohere-command-r-plus-08-2024
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.66
    quality_sensitivity: 1.85
    latency_ms: 920
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.5
    thinking: 0.62
    general: 0.78
    instruction_following: 0.76
    image: -0.8
- id: cohere/Cohere-command-r-08-2024
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.6
    quality_sensitivity: 1.65
    latency_ms: 840
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.48
    thinking: 0.58
    general: 0.76
    instruction_following: 0.74
    image: -0.8
- id: cohere/cohere-command-a
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.58
    quality_sensitivity: 1.6
    latency_ms: 820
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.46
    thinking: 0.56
    general: 0.75
    instruction_following: 0.74
    image: -0.8
- id: mistral-ai/mistral-small-2503
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.58
    quality_sensitivity: 1.6
    latency_ms: 800
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: economy
  type: text
  task_affinity:
    coding: 0.5
    thinking: 0.58
    general: 0.75
    instruction_following: 0.72
    image: -0.8
- id: mistral-ai/Codestral-2501
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.62
    quality_sensitivity: 1.75
    latency_ms: 860
    failure_rate: 0.03
  metadata_preset: code_ctx128000_out4096
  tier: balanced
  type: coding
  task_affinity:
    coding: 1.0
    thinking: 0.64
    general: 0.56
    instruction_following: 0.48
    image: -0.9
- id: mistral-ai/mistral-medium-2505
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.64
    quality_sensitivity: 1.8
    latency_ms: 900
    failure_rate: 0.03
  metadata_preset: chat_ctx128000_out8192
  tier: balanced
  type: text
  task_affinity:
    coding: 0.54
    thinking: 0.64
    general: 0.77
    instruction_following: 0.74
    image: -0.8
- id: mistral-ai/Ministral-3B
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.5
    quality_sensitivity: 1.35
    latency_ms: 700
    failure_rate: 0.03
  metadata_preset: chat_ctx32768_out4096
  tier: economy
  type: text
  task_affinity:
    coding: 0.4
    thinking: 0.46
    general: 0.7
    instruction_following: 0.68
    image: -0.8
- id: deepseek/DeepSeek-V3-0324
  provider: github
  costs:
    input_per_1k: 0.0
    output_per_1k: 0.0
  priors:
    quality_bias: 0.66
    quality_sensitivity: 1.9
    latency_ms: 940
    failure_rate: 0.03
  metadata_preset: reasoning_ctx128000_out8192
  tier: balanced
  type: reasoning
  task_affinity:
    coding: 0.62
    thinking: 0.88
    general: 0.74
    instruction_following: 0.64
    image: -0.7
